{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('env': venv)"
    },
    "kubeflow_notebook": {
      "docker_image": "",
      "experiment_name": "titanic",
      "pipeline_description": "Predict which passengers survived the Titanic shipwreck",
      "pipeline_name": "titanic-ml",
      "volumes": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "colab": {
      "name": "layer-kubeflow-titanic-demo.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7653cfad014d99222cd9ec62c133ef3cd94204ea0f72955d8d62e449b13d793d"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TVgbEMtEAyN"
      },
      "source": [
        "## Machine Learning on Titanic passengers survival data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8yTOjklEAyU"
      },
      "source": [
        "This Notebook will use machine learning to create a model that predicts which passengers survived the Titanic shipwreck. The dataset provides information on the fate of passengers on the Titanic, summarized according to economic status (class), sex, age and survival.\n",
        "\n",
        "Credit for this Notebook goes to Niklas Donges, who published a very detailed post [here](https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8). Check it out if you want to dive deeper in the data analysis and machine learning details of the challenge."
      ]
    },
    {
      "source": [
        "## Install requirements for this notebook"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installing missing requirements\r\n",
        "# Best practice to use your custom image, to not have to do this repeatedly.\r\n",
        "\r\n",
        "!pip install --user -r requirements.txt\r\n",
        "\r\n",
        "# Restart the kernel and run the next code cell."
      ]
    },
    {
      "source": [
        "# Import dependencies and load data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "imports"
        ],
        "id": "vfHvAxWdEAyX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "block:loaddata"
        ],
        "id": "BSIcO5e4EAyY"
      },
      "source": [
        "path = \"data/\"\n",
        "\n",
        "PREDICTION_LABEL = 'Survived'\n",
        "\n",
        "test_df = pd.read_csv(path + \"test.csv\")\n",
        "train_df = pd.read_csv(path + \"train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih2FMEdVEAyZ"
      },
      "source": [
        "#### Let's explore the data\n",
        "\n",
        "These are features of the dataset:\n",
        "```\n",
        "survival:    Survival \n",
        "PassengerId: Unique Id of a passenger. \n",
        "pclass:    Ticket class     \n",
        "sex:    Sex     \n",
        "Age:    Age in years     \n",
        "sibsp:    # of siblings / spouses aboard the Titanic     \n",
        "parch:    # of parents / children aboard the Titanic     \n",
        "ticket:    Ticket number     \n",
        "fare:    Passenger fare     \n",
        "cabin:    Cabin number     \n",
        "embarked:    Port of Embarkation\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "skip"
        ],
        "id": "KGpqDlz2EAya",
        "outputId": "84d698ad-cf4c-473f-a934-9d0ed1138403"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            "PassengerId    891 non-null int64\n",
            "Survived       891 non-null int64\n",
            "Pclass         891 non-null int64\n",
            "Name           891 non-null object\n",
            "Sex            891 non-null object\n",
            "Age            714 non-null float64\n",
            "SibSp          891 non-null int64\n",
            "Parch          891 non-null int64\n",
            "Ticket         891 non-null object\n",
            "Fare           891 non-null float64\n",
            "Cabin          204 non-null object\n",
            "Embarked       889 non-null object\n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ7YjKL9EAyh"
      },
      "source": [
        "## DATA PROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSdPwf3gEAyh"
      },
      "source": [
        "#### SibSp and Parch\n",
        "\n",
        "Combine these two features as the number of relatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "block:datapreprocessing",
          "prev:loaddata"
        ],
        "id": "dL6ywq6uEAyh",
        "outputId": "501d095f-4d9d-4a77-ab34-290af82aebe4"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
        "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
        "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
        "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
        "train_df['not_alone'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    537\n",
              "0    354\n",
              "Name: not_alone, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qkzDw61EAyi"
      },
      "source": [
        "# This does not contribute to a person survival probability\n",
        "train_df = train_df.drop(['PassengerId'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVqpN_aQEAyi"
      },
      "source": [
        "#### Missing data: Cabin\n",
        "\n",
        "Create a new `Deck` feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZH_ZY_EAyj"
      },
      "source": [
        "import re\n",
        "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
        "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
        "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
        "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
        "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
        "# we can now drop the cabin feature\n",
        "train_df = train_df.drop(['Cabin'], axis=1)\n",
        "test_df = test_df.drop(['Cabin'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTmLeqXbEAyj"
      },
      "source": [
        "#### Missing data: Age\n",
        "\n",
        "Fill missing data from age feature with a random sampling from the distribution of the existing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK3Ec0WFEAyj",
        "outputId": "9bd90730-8530-4615-f227-207e95a2e2fb"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    mean = train_df[\"Age\"].mean()\n",
        "    std = test_df[\"Age\"].std()\n",
        "    is_null = dataset[\"Age\"].isnull().sum()\n",
        "    # compute random numbers between the mean, std and is_null\n",
        "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
        "    # fill NaN values in Age column with random values generated\n",
        "    age_slice = dataset[\"Age\"].copy()\n",
        "    age_slice[np.isnan(age_slice)] = rand_age\n",
        "    dataset[\"Age\"] = age_slice\n",
        "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
        "train_df[\"Age\"].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqhzA5p6EAyk"
      },
      "source": [
        "#### Missing data: Embarked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaN_128lEAyk",
        "outputId": "82e969a4-a7b4-427a-c836-037525f0c3ab"
      },
      "source": [
        "train_df['Embarked'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     889\n",
              "unique      3\n",
              "top         S\n",
              "freq      644\n",
              "Name: Embarked, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifzSuZi0EAyl"
      },
      "source": [
        "# fill with most common value\n",
        "common_value = 'S'\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJsyaKCrEAyl"
      },
      "source": [
        "#### Convert Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SZ5NoGbEAyl",
        "outputId": "c15d6c07-ebc4-4a89-d562-d5674e94423c"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 13 columns):\n",
            "Survived     891 non-null int64\n",
            "Pclass       891 non-null int64\n",
            "Name         891 non-null object\n",
            "Sex          891 non-null object\n",
            "Age          891 non-null int64\n",
            "SibSp        891 non-null int64\n",
            "Parch        891 non-null int64\n",
            "Ticket       891 non-null object\n",
            "Fare         891 non-null float64\n",
            "Embarked     891 non-null object\n",
            "relatives    891 non-null int64\n",
            "not_alone    891 non-null int64\n",
            "Deck         891 non-null int64\n",
            "dtypes: float64(1), int64(8), object(4)\n",
            "memory usage: 90.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "block:featureengineering",
          "prev:datapreprocessing"
        ],
        "id": "9oKxfcB5EAyl"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ieVGE-EAym"
      },
      "source": [
        "#### Titles features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMTl1kk4EAym"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "\n",
        "for dataset in data:\n",
        "    # extract titles\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # replace titles with a more common title or as Rare\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
        "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    # convert titles into numbers\n",
        "    dataset['Title'] = dataset['Title'].map(titles)\n",
        "    # filling NaN with 0, to get safe\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "train_df = train_df.drop(['Name'], axis=1)\n",
        "test_df = test_df.drop(['Name'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S--2lIcjEAym"
      },
      "source": [
        "#### Sex into numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLTTjeAdEAym"
      },
      "source": [
        "genders = {\"male\": 0, \"female\": 1}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Sex'] = dataset['Sex'].map(genders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHZgFAtREAyn"
      },
      "source": [
        "#### Drop Ticket feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDSY2uzpEAyn"
      },
      "source": [
        "train_df = train_df.drop(['Ticket'], axis=1)\n",
        "test_df = test_df.drop(['Ticket'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJChi3AEAyn"
      },
      "source": [
        "#### Embarked into numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJFufZtFEAyn"
      },
      "source": [
        "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].map(ports)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLDmQbLiEAyn"
      },
      "source": [
        "#### Age into categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA158UDgEAyo"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
        "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
        "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
        "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
        "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
        "\n",
        "# let's see how it's distributed train_df['Age'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXHk700QEAyo"
      },
      "source": [
        "#### Fare into categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHKf_Yu5EAyo"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
        "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
        "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq_rshDsEAyo"
      },
      "source": [
        "## New Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLzYXQZUEAyo"
      },
      "source": [
        "#### Age times Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxJsszU6EAyp"
      },
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVU5X21OEAyv"
      },
      "source": [
        "#### Fare per person"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltK40e3xEAyv",
        "outputId": "c445a6e7-9a84-4795-8c77-7ebe47416a3e"
      },
      "source": [
        "for dataset in data:\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
        "# Let's take a last look at the training set, before we start training the models.\n",
        "train_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  relatives  \\\n",
              "0         0       3    0    2      1      0     0         0          1   \n",
              "1         1       1    1    5      1      0     3         1          1   \n",
              "2         1       3    1    3      0      0     0         0          0   \n",
              "3         1       1    1    5      1      0     3         0          1   \n",
              "4         0       3    0    5      0      0     1         0          0   \n",
              "5         0       3    0    4      0      0     1         2          0   \n",
              "6         0       1    0    6      0      0     3         0          0   \n",
              "7         0       3    0    0      3      1     2         0          4   \n",
              "8         1       3    1    3      0      2     1         0          2   \n",
              "9         1       2    1    1      1      0     2         1          1   \n",
              "\n",
              "   not_alone  Deck  Title  Age_Class  Fare_Per_Person  \n",
              "0          0     8      1          6                0  \n",
              "1          0     3      3          5                1  \n",
              "2          1     8      2          9                0  \n",
              "3          0     3      3          5                1  \n",
              "4          1     8      1         15                1  \n",
              "5          1     8      1         12                1  \n",
              "6          1     5      1          6                3  \n",
              "7          0     8      4          0                0  \n",
              "8          0     8      3          9                0  \n",
              "9          0     8      3          2                1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYW2PUC5EAyw"
      },
      "source": [
        "## ML\n",
        "\n",
        "Because the dataset does not provide labels for their testing-set, we need to use the predictions on the training set to compare the algorithms with each other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhubRtwgEAyz"
      },
      "source": [
        "train_labels = train_df[PREDICTION_LABEL]\n",
        "train_df = train_df.drop(PREDICTION_LABEL, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qMYaXZVEAyz"
      },
      "source": [
        "\n",
        "\n",
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "block:randomforest",
          "prev:featureengineering"
        ],
        "id": "X8vDLCiVEAy0"
      },
      "source": [
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(train_df, train_labels)\n",
        "acc_random_forest = round(random_forest.score(train_df, train_labels) * 100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsaMow57EAy5"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(acc_random_forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C_RkqrCE_jR"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0gp3DXgE9f_"
      },
      "source": [
        "filename = 'RF_model.sav'\n",
        "joblib.dump(random_forest, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ1MmkcoFg9o"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkT5MXVGFgcK"
      },
      "source": [
        "loaded_model = joblib.load(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLzcSbjEFouI"
      },
      "source": [
        "### Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMyZ108QFqL5"
      },
      "source": [
        "from kale.common.serveutils import serve\n",
        "\n",
        "kfserving = serve(loaded_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blcItL-pGldK"
      },
      "source": [
        "\n",
        "Simulating a request from a client application from already preprocessed features:\n",
        "\n",
        "`\"Pclass\": 3`, \n",
        "\n",
        "`\"Sex\": 0`, \n",
        "\n",
        "`\"Age\": 4`, \n",
        "\n",
        "`\"SibSp\": 1`, \n",
        "\n",
        "`\"Parch\": 2`, \n",
        "\n",
        "`\"Fare\": 3`,  \n",
        "\n",
        "`\"Embarked\": 0`, \n",
        "\n",
        "`\"relatives\": 1`, \n",
        "\n",
        "`\"not_alone\": 0`, \n",
        "\n",
        "`\"Deck\": 8`, \n",
        "\n",
        "`\"Title\": 3`, \n",
        "\n",
        "`\"Age_Class\": 6`, \n",
        "\n",
        "`\"Fare_Per_Person\": 2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN5-IEZjFuwB"
      },
      "source": [
        "import json\n",
        "data = {\"instances\": [[3, 0, 4, 1, 2, 3, 0, 1, 0, 8, 3, 6,2]]}\n",
        "response = kfserving.predict(json.dumps(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRGKi9QiF2ZN"
      },
      "source": [
        "print(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u2tphHdF6Bt"
      },
      "source": [
        "# Alternarively call from the terminal\n",
        "# export MODEL_DEPLOYMENT_URL=<ENTER YOUR INTER MODEL DEPLOYMENT URL HERE>\n",
        "# curl --header \"Content-Type: application/json; format=pandas-records\"   --request POST   --data  '{\"instances\": [[3, 0, 4,1, 2,3,0, 1,0,8,3,6,2]]}'  $MODEL_DEPLOYMENT_URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Congratulations! You have now built and served an end-to-end ML Pipeline with Kubeflow Pipelines and Kale"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}